# -*- coding: utf-8 -*-
"""NLP_Tokenization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18E2qhDOx_2WQ5BbxRESMhoVC7FTJ4kp-
"""

! pip install nltk

corpus = """Hii! I am Darshika.
I am doing my PG in AI field!!
i am 23 years old. """

corpus

print(corpus)

"""Tokenization -> corpus to documents (paragragh to sentence)"""

from nltk.tokenize import sent_tokenize
import nltk
nltk.download('punkt_tab')

document = sent_tokenize(corpus)   ## give list of sentence

for docs in document:
  print(docs)

from nltk.tokenize import word_tokenize

word_tokenize(corpus)
# word_tokenize(docs)

word_tokenize(docs)

for docs in document:
  print(word_tokenize(docs))

from nltk.tokenize import TreebankWordTokenizer

tokenizer = TreebankWordTokenizer()
tokenizer.tokenize(corpus)

